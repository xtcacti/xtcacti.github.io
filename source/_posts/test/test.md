---
title: test - 软件测试基础篇
date: 2021-04-19 20:43:12
tags: test
---

# 软件测试基础篇

## 从用户登录谈起

1. 用户登录 <不及格版>

- 输入用户名密码
- 点击登录
- 验证是否登陆成功

2. 但是，作为测试工程师，要保证系统在各个应用场景下的功能是符合设计要求的，所以需要设计更多更全面的测试用例

- 等价类划分
  - 将所有可能输入的数据划分为若干个子集，每一个子集的任何一个数据对于揭露程序中存在的典型错误都有同等效果，那么一个子集就是一个等价类。在测试时，一个子集选取一个数据就可以用少量具有代表性的测试输入取得较好的测试覆盖结果
- 边界值分析
  - 选取输入、输出值的边界值进行测试。通常大量的软件错误发生在输入或输出的范围边界上，所以需要对边界值进行重点测试。比如选取正好等于、刚刚大于或小于的边界值作为测试数据。
- 等价类划分和边界值分析都属于典型的黑盒测试方法。边界值分析法正好是对等价类划分的补充，所以通常结合起来使用。

3. 用户登录测试用例优化：<及格版>

- 输入已注册用户名和正确密码登录 -> 验证是否登录成功；
- 输入已注册用户名和不正确的密码登录 -> 验证是否失败，并提示信息正确
- 输入未注册用户名和任意密码 -> 验证是否失败，并提示信息正确
- 用户名密码都为空 -> 验证是否失败，并提示信息正确
- 用户名密码之一为空 -> 验证是否失败，并提示信息正确
- 若有验证码，输入正确用户名密码，正确验证码 -> 验证是否登录成功
- 若有验证码，输入正确用户名密码，不正确验证码 -> 验证是否登录失败，并提示信息正确

4. 用户登录测试用例 zai 优化：<良好版> 显性功能完整了

- 用户名密码是否大小写敏感
- 页面密码框是否加密显示
- 后台系统创建的用户，第一次登陆成功，是否提示修改密码
- 忘记用户名和忘记密码功能是否可用
- 前端页面是否根据设计要求对用户名密码限制长度
- 如果有验证码，点击验证码图片是否会更新验证码，更新后的验证码是否可用
- 刷新页面是否会刷新验证码
- 如果验证码有时效性，需要对时效内和时效外的验证码分别做校验
- 用户登陆成功后，会话超时，是否会重定向到用户登录页面
- 不同级别的用户，比如管理员和普通用户，登录系统后的权限是否正确
- 页面默认聚焦是否定位在用户名的输入框中
- 快捷键 tab 和 enter 是否可以正常使用
  - 所谓显性就是肉眼可见的功能测试，以上用例都是基于显性的功能测试，质量过硬的软件系统，除了显示的 功能需求外，还有非功能性需求即隐形需求。
  - 非功能性需求：
    - 安全性、
    - 性能、
    - 兼容性
  - 非功能性需求测试，往往正是决定软件质量的关键

5. 用户登录测试用例 zai 优化：<优秀版> 隐性功能完整了

- 安全性：
  - 用户密码后台存储是否加密
  - 用户密码在网络传输过程中是否加密
  - 密码是否具有时效性，密码到期后是否提示修改密码
  - 不登陆的情况下，在浏览器中直接输入登陆后的 url，是否会直接重定向到用户登录界面
  - 密码输入框是否不支持复制和粘贴
  - 密码输入框输入的密码是否都可以在页面源码模式下被查看
  - 用户名和密码的输入框分别输入典型的`SQL注入攻击`字符串,验证系统返回界面
  - 用户名和密码输入框分别输入典型的`XSS跨站脚本攻击`字符串，验证系统行为是否被篡改
  - 连续多次登录失败之后，系统是否会阻止后续的尝试以应对暴力破解
  - 同一用户在同一终端的多种浏览器登录，验证登录功能的互斥性是否符合设计预期
  - 同一用户先后在多台终端的浏览器登录，验证登录时候具有互斥性
- 性能测试：
  - 单用户登录的响应时间是否小于 3 秒
  - 单用户登录，后台请求数量是否过多
  - 高并发场景下用户登录的响应时间是否小于 5 秒
  - 高并发场景下，服务端的监控指标是否符合预期
  - 高集合点并发场景下，是否存在资源死锁和不合理的资源等待
  - 长时间大量用户连续登录和登出，服务器端是否存在内存泄漏
- 兼容性测试
  - 不同的浏览器下，验证登陆页面的显示功能是否正确
  - 相同浏览器的不同版本，验证登陆页面的显示功能是否正确
  - 不同的移动终端的不同浏览器下，...
  - 不同的分辨率界面下，...

6. 测试之路，遥遥无期，没有穷尽(穷尽测试),但实际工作，由于时间程本和经济成本，无法完成穷尽测试，所以采用基于风险驱动模式，有所侧重的选择测试范围和设计测试用例，寻求缺陷风险和研发成本之间的平衡。

7. 登录补充用例：

- 网络延迟、弱网络、切换网络、断网时是否能正常登录
- 是否支持第三方登录
- 是否可以记住密码（密码有效期过了，是否会清除密码）
- 是否支持特殊字符和中文
- 是否可以使用登录的 API 发送登录请求，并绕开验证码校验
- 是否可以用抓包工具抓到的请求包直接登录
- 截取到的 token 等信息，是否可以在其他终端直接使用，绕开登录，token 过期时间校验
- 登录后输入登录的 URL 之后，是否还能再次登录

## 如何设计一个“好的”测试用例

- 池塘捕鱼 傻子吃大饼

1. 好的测试用例的特点：

- 整体完备性
- 等价类划分的准确性
- 等价类划分的完备性

2. 三种常用的软件测试方法
   学生信息系统的考试成绩输入项 0-100 分的范围

- 等价类划分
  - 有效等价类：0~59 59~100
  - 无效等价类：小于 0 大于 100 0~100 之间的浮点数 非数字
- 边界值分析 对等价类划分的补充
  - -1 0 1 59 60 61 99 100 101
- 错误推测
  - 基于对被测软件系统设计的理解，结合个人经验直觉，推测书软件可能存在的缺陷，从而针对性的设计测试用例方法，过度依赖个人能力
  - 与探索是测试方法的基本思想和理念不谋而合，这个方法在敏捷开发模式下投入产出比很高
  - e.g.
    - Web GUI 功能测试需要考虑浏览器在有缓存无缓存下的表现
    - Web Service API 测试考虑被测 API 所依赖的第三方 API 出错下的处理逻辑
    - 代码级单元测试，需要考虑被测函数输入为空的情况下的内部处理逻辑
  - 企业为了降低对个人能力的依赖，一般会维护缺陷知识库，对中小企业就是建立简单的 wiki 页面，手动补充
  - 对于测试基础架构比较成熟的中大型软件企业，通常会以该缺陷知识库作为数据驱动测试的输入来自动生成部分的测试数据

3. 真正的工程实践中，不同的软件项目在研发生命周期的各个阶段都有不同的测试类型

- 开发阶段 - 单元测试
- 软件模块集成阶段 - 代码继承测试
- 打包部署后 - 面向终端用户的 GUI 测试
- 电商网站 - 服务器端基于 API 的测试、中间件测试、GUI 测试等等

4. 用例设计的其他经验

- 只有深入理解被测软件的架构，才能设计出有的放矢的用例集，去发现系统边界以及系统集成上的潜在缺陷
  - 一定不能把被测系统看成一个大黑盒，必须对内部的架构有清楚的认识，比如数据库的连接方式、数据库的读写分离、消息中间件 Kafka 的配置、缓存系统的层级分布、第三方系统的集成
- 必须深入理解被测软件的设计与实现细节，深入理解软件内部的处理逻辑
  - 处理流程、分支处理，可以通过代码覆盖率指标找出可能的测试遗漏点
  - 不要以开发代码的实现作为依据去设计用例，否则可能会错上加错
  - 要以原始需求去设计测试用例
- 可以引入需求覆盖率和代码覆盖率来衡量测试执行的完备性，并以此为依据找出测试点

## 单元测试

1. what

- 单元测试是指，对软件中最小的可测试单元在与其他程序相分离的状态下进行检查和验证，通常指函数和类。
- 一般开发来做，保证在最早期以最小成本来保证局部代码的质量
- 通常都是自动化执行

2. how
   驱动代码？桩代码？Mock 代码？

- 代码的基本特征与产生错误的原因
  - 条件分支、循环处理、函数调用
  - 任何一个分类遗漏、分类错误、分类逻辑错误都会产生缺陷
  - 开发设计逻辑功能正确的代码时会思考：
    - 哪几种正常的输入 - 等价类划分思想
    - 特殊的边界输入 - 边界分析思想
    - 潜在非法输入的处理 - 错误推测思想
- 单元测试用例详解
  - 单元测试的用例是一个“输入数据”和“预计输出”的集合
  - 输入数据：
    - 被测函数的输入参数
    - 被测函数内部需要读取的全局静态变量
    - 被测函数内部需要读取的成员变量
    - 函数内部调用子函数获得的数据
    - 函数内部调用子函数改写的数据
    - 嵌入式系统中，在中断调用时改写的数据
    - ...
  - 预计输出：
    - 被测函数的返回值
    - 被测函数的输出参数
    - 被测函数所改写的成员变量
    - 被测函数所改写的全局变量
    - 被测函数中进行的文件更新
    - 被测函数中进行的数据库更新
    - 被测函数中进行的消息队列更新
    - ...
- 驱动代码、桩代码、Mock 代码
  - 驱动代码时是用来调用被测函数的
  - 桩代码和 Mack 代码是用来替代被测函数调用的函数的一个临时代码
- 单元测试选型：
  - Java - Junit/TestNG
- 桩代码、Mock 代码选型工作是由开发架构师和测试架构师共同决定的
- 为了衡量单元测试代码覆盖率，引入代码覆盖率工具
  - Java - JaCoCo
- 最后需要把单元测试执行、代码覆盖率统计和持续集成流水线集成，以确保每次代码递交，都会自动触发单元测试，并在单元测试执行过程中自动统计代码覆盖率，最后以单元测试通过率和代码覆盖率为标准来决定本次代码递交是否能够被接受。
- 单元测试困难需克服：
  - 紧密耦合代码难以隔离
  - 隔离后编译链接运行困难
  - 代码本身可测试性差
  - 无法通过桩代码直接模拟底层函数的调用
  - 代码覆盖率越往后越难以提高

## 自动化测试

1. what

- 人对软件测试的行为 -> 机器对软件测试的行为
- 若自动化测试用例维护成本高于其节省的测试成本时，自动化测试就失去了价值与意义

2. why

- 可替代手工机械重复性工作
- 大幅提升回归测试效率，非常适合敏捷开发过程
- 可利用无人值守时间，去频繁执行测试，非工作时间执行测试，工作时间分析报告
- 可完成非常巨大的测试类型，比如关键业务 7\*24 小时持续运行的系统稳定性测试和高并发场景下的压力测试等
- 可保证每次测试执行的操作及验证的一致性和可重复性，避免人为遗漏或疏忽
- ======BUT======
- 脆弱，无法应对系统的变化 ->开发手一抖，自动化测试忙一宿
- 自动化测试程本 = 单词手工测试\*5
- 自动化测试紧紧能发现回归测试的缺陷
- 业务测试专家和自动化测试专家通常是两批人，只有紧密合作，才能高效开展
- 编程能力

3. when

- 需求稳定，不会频繁变更
- 研发和维护周期厂，需频繁执行回归测试
- 软件产品比软件项目更适合，因为产品是一个迭代的过程，迭代就需要回归测试
- 对于软件项目，考虑用 20%的精力覆盖 80%的回归测试，其他功能尽量用探索式测试
- 需要在多个平台上重复运行相同测试的场景
  - 不同浏览器
  - 不同浏览器的不同版本，安卓、IOS 的不同版本
  - 不同客户的不同定制版本，主体功能一致
- 对某些测试项目通过手工无法实现，手工成本太高
  - 性能和压力测试
  - e.g. 一万用户并发量 | 7\*24 小时稳定性测试
  - 就需要基于协议的自动化测试技术了
- 被测软件规范，具有可测试性
  - 比如，GUI 测试的定位元素若无规则可循就没法弄了
  - 验证码需要开发预留测试性接口，否则就只能借助光学字符识别（OCR）技术来对图片验证码进行技术识别，不稳定
- 编程能力
  - 编程学习时间长
  - tester 对自动化测试技术一腔热血，忽略了测试用例的设计，直接影响整体质量

## 各个阶段的自动化测试技术

1. 单元测试自动化技术

- 用例框架代码生成的自动化：TestNG
- 部分测试输入数据自动化生成
- 自动桩代码生成
- 被测代码的自动化静态分析:SOnar Coverity 编码规则规范
- 测试覆盖率的自动统计与分析：自动化工具自动统计各种测试覆盖率

2. 代码级集成自动化技术

- 基本不做

3. WebService 自动化技术

- 就是针对 SOAP API 和 REST API 这两类 API 测试，最典型的就是用 SoapUI 或 Postman 等工具。但这类工具都是界面操作手动发起的 Request 并验证 Response，难以和 CI/CD 集成，于是就出现了 API 自动化测试框架。
- e.g. REST Assured
- 基于代码的 API，包含三大步骤：
  - 测试数据
  - 调用参数并发起 API 调用
  - 验证返回结果
- 测试脚手架代码的自动化生成
- 部分测试输入数据的自动化生成
- Response 验证的自动化
- 基于 SOAPUI 或者 Postman 的自动化脚本的生成
  - 自己实现一个工具，输入时 SOAPUI 或 Postman 的用例元数据，输出是基于 diamagnetic 实现的测试用力了

4. GUI 自动化

- Web
  - Selenium(Open Source)
  - Micro FOcus 的 UFT(前身 QTP) (Bussiness Edition)
- Native App
  - Appium
    - iOS:集成 XCUITest
    - Android：集成 UIAutomator 和 Espresso

## 测试覆盖率
1. 需求覆盖率：面向需求
  - 将每一条软件需求和对应的测试建立一对多的映射关系，最终目标是保证测试可以覆盖每个需求，以保证软件产品的质量。
  - 通常使用ALM、Doors、TestLink等工具来建立需求和测试的对应关系，以保证软件产品的测试质量，也可以此计算测试覆盖率
  - 现在的测试覆盖率通常是指代码覆盖率，而不是需求覆盖率


2. 代码覆盖率：面向技术
  - 行覆盖率
  - 判定覆盖率
  - 条件覆盖率
  - 高的代码覆盖率不一定能保证代码质量、低的代码覆盖率一定不能保证代码覆盖率
  - 一般只有单元测试对代码覆盖率有较高要求，集成测试或GUI测试把代码覆盖率提升到一定量级是要付出巨大代价的


3. 代码覆盖率工具
- JaCoCo: 
  - 一款Java代码主流开源覆盖率工具
  - 可以很方便的嵌入到Ant、Maven中
  - 可以和很多主流的持续集成工具及代码静态检查工具（Jenkins、Sonar）集成 


4. 代码覆盖率工具原理
- 注入
  - 最基本的方法就是注入（Instrumentation）：注入就是在被测代码中自动插入用于覆盖统计的探针（Probo）代码，并保证插入的探针代码不会影响原来的代码
  - 注目标对于Java代码来讲分为，源码和字节码。基于JVM本身特性及执行效率，目前主流工具都基于字节码，注入的具体实现采用ASM技术。
  - ASM是一个Java字节码操纵框架，能被用来动态生成类或者增强既有类的功能，可以直接产生class文件，也可以在类被加载如JVM之前动态改变类行为。
- 根据注入时间分为两大模式
  - On-The-Fly:
    - 无需修改源代码、无需提前进行字节码插桩，适用于支持Java Agent的运行环境
    - 优点：可以在系统不停机的情况下实时收集代码覆盖率信息
    - 缺点：运行环境必须使用Java Agent
    - 两种技术方案：
      - 开发自定义类装载器（Class Loader）来实现类装载策略，每次类加载前，需要在class文件中插入探针
      - 借助Java Agent，利用执行在main()方法之前的拦截器方法premain()来插入探针，实际使用的过程中，需要在JVM的启动参数中添加“-javaagent”，并指定用于实时字节码注入的代理程序，这样的代理程序在装在每个class之前，先判断是否插入了探针，若没有则加入探针。JaCoCo就是这个方式。
  - Offline
    - 无需修改源代码，但是需要在测试开始前先对文件进行插桩，并事先生成插过桩的class文件，它适用于不支持Java Agent的运行环境，以及无法自定义类装载器的场景。
    - 优点：JVM启动时不再需要javaAgent额外开启代理
    - 缺点：无法实时获取代码覆盖率信息，只能在系统停机时获取
    - 根据是直接修改原class文件还是生成新的class文件，分为两大模式：
      - Inject：修改源文件
      - Replace：生成新文件
    - 技术方案：在测试运行前就已经通过ASM将探针插入了class文件，在测试执行过程中不需要任何额外的处理。Cobertura就是这个方式。


## 高效填写软件缺陷报告
1. 缺陷管理系统：ALM、JIRA、Bugzilla、BugFree、Mantis
2. 缺陷标题：在什么情况下发生了什么问题
  - 问题描述，清晰简洁具体
  - 避免停留在问题的表面
  - 不易过长
3. 缺陷概述：缺陷本质与现象
  - 同一类型缺陷可能出现的场景
  - 同样的问题在之前的版本中是否会出现
  - 避免以缺陷重现步骤来描述，而是使用概括性语句
  - 能够使开发工程师聚焦于本质
4. 缺陷影响：对用户及业务的影响范围(优先级)及严重程度,开发经理会以此作为依据来决定修复该缺陷的优先级，产品经理会以此作为依据来衡量缺陷的严重程度进而决定是否要等该缺陷被修复后再发布产品。
5. 环境配置：按需描述，详细描述测试环境的配置细节，为缺陷的重现提供必要的环境信息
  - 操作类型及版本
  - 被测软件版本
  - 浏览器的类型及版本
  - 被测软件的配置信息
  - 集群的配置参数
  - 中间件的版本信息等等
6. 前置条件：缺陷重现的前置条件，比如，用户已完成登录
7. 缺陷重现步骤
  - 测试工程师在写缺陷重现步骤前，需要反复执行测试步骤3次以上
    - 一、确保缺陷的可重现性
    - 二、找到最短的缺陷重现路径、过滤掉非必要的步骤，避免产生不必要的干扰
  - 详细、具体、避免与缺陷不相关的步骤、测试数据ready
8. 期望结果和实际结果
  - 期望结果：描述期待发生什么，而不是不应该发生什么
  - 实际结果：说明发生了什么，而不是什么没发生
9. 优先级Priority & 严重程度Serverity
  - 优先级是缺陷被修复的紧急程度
  - 严重程度是缺陷对产品的影响程度
  - 缺陷严重程度越高、优先级越高
  - 有些缺陷虽然严重程度不高，但是会影响测试或自动化测试，那么优先级就高了
  - 有些缺陷虽然严重程度高，但是修复成本高或修复难度大，那么优先级就低了
10. 变通方案Workaround：严重程度高的缺陷如果有变通方案，那么优先级就可以降低
11. 根原因分析Root Cause Analysis:RCA,在发现缺陷的同时，也能发现缺陷的RC并反馈给开发
12. 附件Attachment：截图并高亮、用例日志、服务端日志、GUI测试的执行视频等

## 做好测试计划
- 一份好的测试计划要包括测试范围、测试策略、测试资源、测试进度、测试风险预估，每一部分都要分别给出应对可能出现问题的解决办法。
1. 测试范围：测什么，不测什么
2. 测试策略：先测什么，后测什么，如何来测，测试类型和方法选型
  - 功能测试：先实现主干业务的测试，选取用于自动化测试的测试点，准备测试数据，评估测试可行性，有问题考虑好测试方案，请开发人员提供测试接口
  - 兼容性测试：web的浏览器类型版本、移动端的设备类型以及Android、IOS版本
    - 通过大数据技术分析产品的历史数据拿去top30%的移动设备以及版本列表，只覆盖这部分即可
    - 全新产品可通过TalkingData查看主流的移动设备、分辨率大小等等来确定测试范围
    - 兼容性测试的实施往往是在功能测试基本稳定了才会开始，也有特例（比如前端引入了新的框架或组件库，就会在前期做兼容性评估）
    - 兼容性测试用例往往选取于已经实现的自动化测试用例，因为兼容性测试往往要覆盖最常用的业务场景，最常用的业务场景也是首批实现自动化测试的目标。GUI自动化测试框架，需要能够支持同一套脚本在不做修改的前提下，运行于不同的浏览器。
  - 性能测试：在明确了解性能需求（并发用户数、响应时间、事务吞吐量等）的前提下，结合被测系统的特点，设计性能测试场景，并确定性能测试框架。
    - 比如，是基于API级别发起压力测试，还是需要模拟终端用户行为进行基于协议的压力测试
    - 再比如，是基于模块进行压力测试，还是发起全链路压测
    - 如果性能是背景数据敏感的场景，还需要确定背景数据量级与分布，并决定产生背景数据的技术方案（API产生数据，还是数据库批量insert & update，还是两种方式结合）
    - 需要明确待开发的单用户脚本的数量，以便后续能够顺利组装压测场景

3. 测试资源
4. 测试人员：谁来测？（测试人员的数量，测试工程师个人经验和能力）
5. 测试环境：在那里测？
6. 测试进度:在明确了测试范围、测试策略和测试资源之后，考虑测试进度，考虑各项测试的开始时间，所需工作量，预计完成时间，并以此为依据建议最终上线发布时间
7. 测试风险评估:
  - 遇到需求变更、开发延期、发现重大缺陷和人员变动都会带来项目测试的风险
  - 需求变更：
    - 增加需求、删减需求、修改需求
    - 一定要重新进行需求分析、确定变更后的测试范围和资源评估
    - 并与项目经理和产品经理及时沟通因此引起的测试进度的变化
    - 测试经理、测试负责人切忌不能有自己咬牙扛过去的想法，否则无论是对测试团队还是产品本身不会有任何好处
  - 测试预估不准确，需要增加更多的测试类型，或因要修改测试架构的严重缺陷而导致很多的测试需要全回归，开发递交测试版本延期，人员变动等各种情况，都需要指定相应的策略。

## 软件测试工程师的核心竞争力
- 业务知识不等于测试能力
- 测试开发->开发是为了服务测试
1. 传统测试工程师
  - 测试策略设计能力：快速理解需求、快速明确测试重点及测试方法
    - 测试具体执行到什么程度
    - 测试需要借助什么工具
    - 如何运用自动化测试及自动化测试框架以及选型
    - 测试资源分配
    - 测试进度安排
    - 测试风险应对方式
  - 测试用例设计能力：体系化的用例设计思维
  - 快速学习能力：不同业务需求的快速学习、测试新技术新方法的快速学习及应用
  - 探索性测试思维：针对开发代码的变更，目标明确并且有针对性地对变更点以及变更关联点做的测试，是敏捷主推测试实践之一。
  - 缺陷分析能力：
    - 对于已发现的缺陷，结合发生错误的上下文以及后台日志，可以预测或者定位缺陷发生的原因，甚至明确出错的代码行，大幅度缩短缺陷的修复周期，并提高开发对测试的认可和信任
    - 根据已发生的缺陷，结合探索性测试推断出可能存在的潜在缺陷
    - 可以对一段时间内发生的缺陷类型和趋势进行合理分析，由点到面的预估整体质量状态，并以此来调整后续的策略。
  - 自动化测试技术
  - 良好的沟通能力
    - 对接产品经理和项目经理，以确保需求的正确实现和项目整体质量的达标
    - 对接开发，确保缺陷的修复与验证
2. 测试开发工程师
  - 测试系统需求分析能力
  - 更广阔的知识体系（测试开发一定能做开发，但是开发不一定能做测试开发）

## 软件测试工程师需要掌握的非测试知识
- 开发是深度遍历，测试是广度遍历，to be a mini系统架构师
1. 小到...
  - Linux/Unix/Windows操作系统
  - Oracle/MySQL传统关系型数据库
  - NoSQL非关系型数据库
  - 中间件技术
  - Shell/Python脚本开发
  - 版本管理工具和策略
  - CI/CD流水线设计
  - F5负载均衡技术
  - Fidder/Wireshark/Tcpdump等抓包工具
  - 浏览器Developer Tool
  - ...
2. 大到...
  - 网站架构设计
  - 容器技术 √
  - 微服务架构
  - 服务架构
  - DevOps √
  - 云计算 √
  - 大数据
  - 人工智能
  - 区块链技术
  - 前端技术
  - ...

## 互联网产品测试策略设计
- 传统软件产品测试回归周期实践充裕比如60小时，互联网产品要求回归测试的执行时间不超过4小时
1. 传统软件产品测试策略：
  - Unit Test：白盒测试，开发自己完成，传统~生命周期长，每次build都会执行单测
  - API Test：灰盒测试，以黑盒的方式来设计调用API测试用例，在测试执行过程中统计代码覆盖率，然后根据代码覆盖情况来补充更有针对的测试用例
  - GUI Test：也称端到端的测试，直接模拟用户行为，用力维护和执行代价大，随机失败率居高不下,仍旧很重量级
2. 互联网产品测试策略：
  - GUI Test: 轻量级，因为敏捷开发，GUI变化频繁，GUI测试用例少
  - API Test：
    - API测试用例的开发与调试效率要比GUI高出很多
    - 稳定性高
    - 执行时间短，更方便的并行执行
    - 对微服务的测试，本质就是对Web Services的测试，也就是API测试
    - API接口改动小，可复用性高，即使改动，也要保证向后兼容，ROI（投入产出比）高
  - Unit Test：轻量级，互联网单测只针对哪些相对稳定的核心模块和服务，应用层上层业务很少会大规模展开单测。


> 声明：本站所有内容仅供个人学习娱乐笔记所用，如涉侵权，请联系删除

# API 自动化测试



## 微服务模式下的 API 测试

# 代码测试

## ------------------

## 代码测试的理念 & 方法

## 静态测试方法

## 动态测试方法

# 性能测试

## ------------------

## 软件性能 & 性能指标

## 性能测试基本方法 & 应用领域

## 后端性能测试工具 & 工具原理

## 前端性能测试工具 & 工具原理

## LoadRunner 企业级服务器端性能测试

## 企业级实际性能测试

# 测试数据准备

## ------------------

## 如何准备测试数据

## 测试数据的痛点

## 统一测试数据平台

# 测试基础架构

## ------------------

## Selenium Grid

## 测试环境架构设计

## 大型电商测试基础架构设计

# 测试新技术

## ------------------

## 探索是测试

## 测试驱动开发(TDD)

## 精准测试

## 渗透测试

## 基于模型的测试

# 测试人员互联网架构核心知识

## ------------------

## 为啥摇动大型网站架构设计

## 网站高性能架构设计

## 网站高可用架构设计

## 网站可扩展性架构设计
